{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1e4ee3-b40d-4fb6-9514-d84aa39bf05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc18329d760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
    "import os\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "import biotite.structure as bs\n",
    "from biotite.structure.io.pdbx import PDBxFile, get_structure\n",
    "from biotite.database import rcsb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import SingleLetterAlphabet\n",
    "\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from linear_quant import *\n",
    "\n",
    "import esm\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1521b40d-e276-4c2c-a303-ac051cbed7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
    "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "deletekeys[\".\"] = None\n",
    "deletekeys[\"*\"] = None\n",
    "translation = str.maketrans(deletekeys)\n",
    "\n",
    "def read_sequence(filename: str) -> Tuple[str, str]:\n",
    "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
    "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
    "    return record.description, str(record.seq)\n",
    "\n",
    "def remove_insertions(sequence: str) -> str:\n",
    "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "    return sequence.translate(translation)\n",
    "\n",
    "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
    "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276db878-1a76-46b3-b89d-54b46df51bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(a, b, c, L, A, D):\n",
    "    \"\"\"\n",
    "    input:  3 coords (a,b,c), (L)ength, (A)ngle, and (D)ihedral\n",
    "    output: 4th coord\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize(x):\n",
    "        return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n",
    "\n",
    "    bc = normalize(b - c)\n",
    "    n = normalize(np.cross(b - a, bc))\n",
    "    m = [bc, np.cross(n, bc), n]\n",
    "    d = [L * np.cos(A), L * np.sin(A) * np.cos(D), -L * np.sin(A) * np.sin(D)]\n",
    "    return c + sum([m * d for m, d in zip(m, d)])\n",
    "\n",
    "\n",
    "def contacts_from_pdb(\n",
    "    structure: bs.AtomArray,\n",
    "    distance_threshold: float = 8.0,\n",
    "    chain: Optional[str] = None,\n",
    ") -> np.ndarray:\n",
    "    mask = ~structure.hetero\n",
    "    if chain is not None:\n",
    "        mask &= structure.chain_id == chain\n",
    "\n",
    "    N = structure.coord[mask & (structure.atom_name == \"N\")]\n",
    "    CA = structure.coord[mask & (structure.atom_name == \"CA\")]\n",
    "    C = structure.coord[mask & (structure.atom_name == \"C\")]\n",
    "\n",
    "    Cbeta = extend(C, N, CA, 1.522, 1.927, -2.143)\n",
    "    dist = squareform(pdist(Cbeta))\n",
    "    \n",
    "    contacts = dist < distance_threshold\n",
    "    contacts = contacts.astype(np.int64)\n",
    "    contacts[np.isnan(dist)] = -1\n",
    "    return contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e0d58b-da6a-44d4-a1cd-3f75ae750bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sequences from the MSA to maximize the hamming distance\n",
    "# Alternatively, can use hhfilter \n",
    "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
    "    assert mode in (\"max\", \"min\")\n",
    "    if len(msa) <= num_seqs:\n",
    "        return msa\n",
    "    \n",
    "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
    "\n",
    "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
    "    all_indices = np.arange(len(msa))\n",
    "    indices = [0]\n",
    "    pairwise_distances = np.zeros((0, len(msa)))\n",
    "    for _ in range(num_seqs - 1):\n",
    "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
    "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
    "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
    "        shifted_index = optfunc(shifted_distance)\n",
    "        index = np.delete(all_indices, indices)[shifted_index]\n",
    "        indices.append(index)\n",
    "    indices = sorted(indices)\n",
    "    return [msa[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa8e003-604d-486f-a260-99575fe0363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precisions(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    src_lengths: Optional[torch.Tensor] = None,\n",
    "    minsep: int = 6,\n",
    "    maxsep: Optional[int] = None,\n",
    "    override_length: Optional[int] = None,  # for casp\n",
    "):\n",
    "    if isinstance(predictions, np.ndarray):\n",
    "        predictions = torch.from_numpy(predictions)\n",
    "    if isinstance(targets, np.ndarray):\n",
    "        targets = torch.from_numpy(targets)\n",
    "    if predictions.dim() == 2:\n",
    "        predictions = predictions.unsqueeze(0)\n",
    "    if targets.dim() == 2:\n",
    "        targets = targets.unsqueeze(0)\n",
    "    override_length = (targets[0, 0] >= 0).sum()\n",
    "\n",
    "    # Check sizes\n",
    "    if predictions.size() != targets.size():\n",
    "        raise ValueError(\n",
    "            f\"Size mismatch. Received predictions of size {predictions.size()}, \"\n",
    "            f\"targets of size {targets.size()}\"\n",
    "        )\n",
    "    device = predictions.device\n",
    "\n",
    "    batch_size, seqlen, _ = predictions.size()\n",
    "    seqlen_range = torch.arange(seqlen, device=device)\n",
    "\n",
    "    sep = seqlen_range.unsqueeze(0) - seqlen_range.unsqueeze(1)\n",
    "    sep = sep.unsqueeze(0)\n",
    "    valid_mask = sep >= minsep\n",
    "    valid_mask = valid_mask & (targets >= 0)  # negative targets are invalid\n",
    "\n",
    "    if maxsep is not None:\n",
    "        valid_mask &= sep < maxsep\n",
    "\n",
    "    if src_lengths is not None:\n",
    "        valid = seqlen_range.unsqueeze(0) < src_lengths.unsqueeze(1)\n",
    "        valid_mask &= valid.unsqueeze(1) & valid.unsqueeze(2)\n",
    "    else:\n",
    "        src_lengths = torch.full([batch_size], seqlen, device=device, dtype=torch.long)\n",
    "\n",
    "    predictions = predictions.masked_fill(~valid_mask, float(\"-inf\"))\n",
    "\n",
    "    x_ind, y_ind = np.triu_indices(seqlen, minsep)\n",
    "    predictions_upper = predictions[:, x_ind, y_ind]\n",
    "    targets_upper = targets[:, x_ind, y_ind]\n",
    "\n",
    "    topk = seqlen if override_length is None else max(seqlen, override_length)\n",
    "    indices = predictions_upper.argsort(dim=-1, descending=True)[:, :topk]\n",
    "    topk_targets = targets_upper[torch.arange(batch_size).unsqueeze(1), indices]\n",
    "    if topk_targets.size(1) < topk:\n",
    "        topk_targets = F.pad(topk_targets, [0, topk - topk_targets.size(1)])\n",
    "\n",
    "    cumulative_dist = topk_targets.type_as(predictions).cumsum(-1)\n",
    "\n",
    "    gather_lengths = src_lengths.unsqueeze(1)\n",
    "    if override_length is not None:\n",
    "        gather_lengths = override_length * torch.ones_like(\n",
    "            gather_lengths, device=device\n",
    "        )\n",
    "\n",
    "    gather_indices = (\n",
    "        torch.arange(0.1, 1.1, 0.1, device=device).unsqueeze(0) * gather_lengths\n",
    "    ).type(torch.long) - 1\n",
    "\n",
    "    binned_cumulative_dist = cumulative_dist.gather(1, gather_indices)\n",
    "    binned_precisions = binned_cumulative_dist / (gather_indices + 1).type_as(\n",
    "        binned_cumulative_dist\n",
    "    )\n",
    "\n",
    "    pl5 = binned_precisions[:, 1]\n",
    "    pl2 = binned_precisions[:, 4]\n",
    "    pl = binned_precisions[:, 9]\n",
    "    auc = binned_precisions.mean(-1)\n",
    "\n",
    "    return {\"AUC\": auc, \"P@L\": pl, \"P@L2\": pl2, \"P@L5\": pl5}\n",
    "\n",
    "\n",
    "def evaluate_prediction(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    ") -> Dict[str, float]:\n",
    "    if isinstance(targets, np.ndarray):\n",
    "        targets = torch.from_numpy(targets)\n",
    "    contact_ranges = [\n",
    "        (\"local\", 3, 6),\n",
    "        (\"short\", 6, 12),\n",
    "        (\"medium\", 12, 24),\n",
    "        (\"long\", 24, None),\n",
    "    ]\n",
    "    metrics = {}\n",
    "    targets = targets.to(predictions.device)\n",
    "    for name, minsep, maxsep in contact_ranges:\n",
    "        rangemetrics = compute_precisions(\n",
    "            predictions,\n",
    "            targets,\n",
    "            minsep=minsep,\n",
    "            maxsep=maxsep,\n",
    "        )\n",
    "        for key, val in rangemetrics.items():\n",
    "            metrics[f\"{name}_{key}\"] = val.item()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88854c1a-c155-405d-a023-1e895d19d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adapted from: https://github.com/rmrao/evo/blob/main/evo/visualize.py\"\"\"\n",
    "def plot_contacts_and_predictions(\n",
    "    predictions: Union[torch.Tensor, np.ndarray],\n",
    "    contacts: Union[torch.Tensor, np.ndarray],\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    # artists: Optional[ContactAndPredictionArtists] = None,\n",
    "    cmap: str = \"Blues\",\n",
    "    ms: float = 1,\n",
    "    title: Union[bool, str, Callable[[float], str]] = True,\n",
    "    animated: bool = False,\n",
    ") -> None:\n",
    "\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "    if isinstance(contacts, torch.Tensor):\n",
    "        contacts = contacts.detach().cpu().numpy()\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    seqlen = contacts.shape[0]\n",
    "    relative_distance = np.add.outer(-np.arange(seqlen), np.arange(seqlen))\n",
    "    bottom_mask = relative_distance < 0\n",
    "    masked_image = np.ma.masked_where(bottom_mask, predictions)\n",
    "    invalid_mask = np.abs(np.add.outer(np.arange(seqlen), -np.arange(seqlen))) < 6\n",
    "    predictions = predictions.copy()\n",
    "    predictions[invalid_mask] = float(\"-inf\")\n",
    "\n",
    "    topl_val = np.sort(predictions.reshape(-1))[-seqlen]\n",
    "    pred_contacts = predictions >= topl_val\n",
    "    true_positives = contacts & pred_contacts & ~bottom_mask\n",
    "    false_positives = ~contacts & pred_contacts & ~bottom_mask\n",
    "    other_contacts = contacts & ~pred_contacts & ~bottom_mask\n",
    "\n",
    "    if isinstance(title, str):\n",
    "        title_text: Optional[str] = title\n",
    "    elif title:\n",
    "        long_range_pl = compute_precisions(predictions, contacts, minsep=24)[\n",
    "            \"P@L\"\n",
    "        ].item()\n",
    "        if callable(title):\n",
    "            title_text = title(long_range_pl)\n",
    "        else:\n",
    "            title_text = f\"Long Range P@L: {100 * long_range_pl:0.1f}\"\n",
    "    else:\n",
    "        title_text = None\n",
    "\n",
    "    img = ax.imshow(masked_image, cmap=cmap, animated=animated)\n",
    "    oc = ax.plot(*np.where(other_contacts), \"o\", c=\"grey\", ms=ms)[0]\n",
    "    fn = ax.plot(*np.where(false_positives), \"o\", c=\"r\", ms=ms)[0]\n",
    "    tp = ax.plot(*np.where(true_positives), \"o\", c=\"b\", ms=ms)[0]\n",
    "    ti = ax.set_title(title_text) if title_text is not None else None\n",
    "    # artists = ContactAndPredictionArtists(img, oc, fn, tp, ti)\n",
    "\n",
    "    ax.axis(\"square\")\n",
    "    ax.set_xlim([0, seqlen])\n",
    "    ax.set_ylim([0, seqlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c99769f-8d33-45d4-9637-f9c31f16b957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import esm\n",
    "from esm.data import ESMStructuralSplitDataset\n",
    "\n",
    "for split_level in ['family', 'superfamily', 'fold']:\n",
    "    for cv_partition in ['0', '1', '2', '3', '4']:\n",
    "        esm_structural_train = ESMStructuralSplitDataset(\n",
    "            split_level=split_level, \n",
    "            cv_partition=cv_partition, \n",
    "            split='train', \n",
    "            root_path = os.path.expanduser('~/.cache/torch/data/esm'),\n",
    "            download=True\n",
    "        )\n",
    "        esm_structural_valid = ESMStructuralSplitDataset(\n",
    "            split_level=split_level, \n",
    "            cv_partition=cv_partition, \n",
    "            split='valid', \n",
    "            root_path = os.path.expanduser('~/.cache/torch/data/esm'),\n",
    "            download=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deaac523-5a8c-419a-8b1c-64cd59a74a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm2 = esm2.eval().cpu()\n",
    "esm2_batch_converter = esm2_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2fc5dc-c04b-44ae-99f1-e2b9783de4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_esm2 = quant_model_acts(esm2, 0, True, exclude_part=[\"base_model\"])\n",
    "quant_esm2 = quant_esm2.cuda(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e7abe74-9757-441e-8d5a-d38e7bb8f931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11207"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(esm_structural_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1c4332-cfed-4380-ae93-dd1658b2eb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4090"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(esm_structural_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22be0e7-4f79-49b5-8618-575bef8554e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    ele = esm_structural_train[i]\n",
    "    data =  [(i, esm_structural_train[i]['seq'])]\n",
    "    batch_labels, batch_strs, batch_tokens = esm2_batch_converter(data)\n",
    "    batch_lens = (batch_tokens != esm2_alphabet.padding_idx).sum(1)\n",
    "    with torch.no_grad():\n",
    "        results = quant_esm2(batch_tokens.cuda(\"cuda:1\"), repr_layers=[33], return_contacts=True)\n",
    "    \n",
    "os.makedirs('./output/stats/', exist_ok=True)\n",
    "act_stats_save_path = './output/stats/act_stats_full_pre_50_v1.pth'\n",
    "act_dict = save_model_act_stats(quant_esm2, act_stats_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3092c2a-cc95-4e6c-bc47-8f7caf428bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm2 = esm2.eval().cpu()\n",
    "# new_model = quant_model_acts(new_model, 8, False, exclude_part=[\"base_model\"], cali_batch_size=50)\n",
    "quant_esm2 = quant_model_acts(esm2, 8, False, exclude_part=[\"base_model\"], cali_batch_size=50, quant_scheme=\"pwlq-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "816f2bbb-b304-433e-9416-b91e5c4a97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = load_model_act_stats(quant_esm2, act_stats_save_path, act_clip_method=\"top_15\")\n",
    "# mode = load_model_act_stats(new_model, act_stats_save_path, act_clip_method=\"clip_0.999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e18b74-1da5-4368-b7c0-c0bf2f85f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "esm2 = esm2.cuda(\"cuda:1\")\n",
    "esm2_results = []\n",
    "\n",
    "for i in range(4090):\n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "    ele = esm_structural_valid[i]\n",
    "    data =  [(i, esm_structural_valid[i]['seq'])]\n",
    "    batch_labels, batch_strs, batch_tokens = esm2_batch_converter(data)\n",
    "    batch_lens = (batch_tokens != esm2_alphabet.padding_idx).sum(1)\n",
    "    with torch.no_grad():\n",
    "        results = esm2(batch_tokens.cuda(\"cuda:1\"), repr_layers=[33], return_contacts=True)\n",
    "        \n",
    "    metrics = {\"id\": i, \"model\": \"ESM-2 (Unsupervised)\"}\n",
    "    metrics.update(evaluate_prediction(results[\"contacts\"], ele['dist'] < 8))\n",
    "    esm2_results.append(metrics)\n",
    "\n",
    "esm2_results = pd.DataFrame(esm2_results)\n",
    "\n",
    "# 4090\n",
    "# 0.6377077553375717\n",
    "# 0.501526620944001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a68acfc-09ac-45c7-8a4d-bd2f1297053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631056543612684\n",
      "0.6361556842394883\n",
      "0.501526620944001\n"
     ]
    }
   ],
   "source": [
    "print(esm2_results[\"local_P@L5\"].mean())\n",
    "print(esm2_results[\"local_P@L2\"].mean())\n",
    "print(esm2_results[\"local_P@L\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce9aba-db06-4b1a-90dc-a0c364aff2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "quant_esm2_results = []\n",
    "quant_esm2 = quant_esm2.cuda(\"cuda:1\")\n",
    "\n",
    "for i in range(4090):\n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "    ele = esm_structural_valid[i]\n",
    "    data =  [(i, esm_structural_valid[i]['seq'])]\n",
    "    batch_labels, batch_strs, batch_tokens = esm2_batch_converter(data)\n",
    "    batch_lens = (batch_tokens != esm2_alphabet.padding_idx).sum(1)\n",
    "    with torch.no_grad():\n",
    "        results = quant_esm2(batch_tokens.cuda(\"cuda:1\"), repr_layers=[33], return_contacts=True)\n",
    "        \n",
    "    metrics = {\"id\": i, \"model\": \"ESM-2 (Unsupervised)\"}\n",
    "    metrics.update(evaluate_prediction(results[\"contacts\"], ele['dist'] < 8))\n",
    "    quant_esm2_results.append(metrics)\n",
    "    \n",
    "quant_esm2_results = pd.DataFrame(quant_esm2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287b1bd-6916-4559-b0f6-bebc00b59eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quant_esm2_results[\"local_P@L5\"].mean())\n",
    "print(quant_esm2_results[\"local_P@L2\"].mean())\n",
    "print(quant_esm2_results[\"local_P@L\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819825eb-b49b-4e47-ab6c-5bcf954a5bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
